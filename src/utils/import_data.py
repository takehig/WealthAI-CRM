#!/usr/bin/env python3
"""
WealthAI ãƒ‡ãƒ¼ã‚¿ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰PostgreSQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹
"""

import pandas as pd
import psycopg2
from psycopg2.extras import execute_values
import os
from pathlib import Path
from dotenv import load_dotenv

# ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿
load_dotenv()

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šè¨­å®š
DB_CONFIG = {
    'host': os.getenv('DB_HOST', 'localhost'),
    'database': os.getenv('DB_NAME', 'crm'),
    'user': os.getenv('DB_USER', 'crm_user'),
    'password': os.getenv('DB_PASSWORD', 'crm123'),
    'port': int(os.getenv('DB_PORT', 5432))
}

def get_db_connection():
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’å–å¾—"""
    return psycopg2.connect(**DB_CONFIG)

def import_csv_to_table(csv_file_path, table_name, columns=None):
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ†ãƒ¼ãƒ–ãƒ«ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"""
    try:
        # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        df = pd.read_csv(csv_file_path)
        print(f"Loading {csv_file_path} -> {table_name} ({len(df)} rows)")
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # ã‚«ãƒ©ãƒ åã‚’æŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯CSVã®ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ä½¿ç”¨
        if columns is None:
            columns = list(df.columns)
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¿ãƒ—ãƒ«ã®ãƒªã‚¹ãƒˆã«å¤‰æ›ï¼ˆNaNã‚’Noneã«å¤‰æ›ï¼‰
        data_tuples = []
        for row in df.values:
            # NaNã‚’Noneã«å¤‰æ›
            converted_row = []
            for value in row:
                if pd.isna(value):
                    converted_row.append(None)
                else:
                    converted_row.append(value)
            data_tuples.append(tuple(converted_row))
        
        # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’ä½œæˆ
        placeholders = ','.join(['%s'] * len(columns))
        columns_str = ','.join(columns)
        
        # INSERTæ–‡ã‚’å®Ÿè¡Œ
        insert_query = f"INSERT INTO {table_name} ({columns_str}) VALUES %s"
        execute_values(cursor, insert_query, data_tuples)
        
        conn.commit()
        cursor.close()
        conn.close()
        
        print(f"âœ… Successfully imported {len(df)} rows to {table_name}")
        
    except Exception as e:
        print(f"âŒ Error importing {csv_file_path}: {str(e)}")
        if 'conn' in locals():
            conn.rollback()
            conn.close()

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å–å¾—
    project_root = Path(__file__).parent.parent.parent
    csv_dir = project_root / "data" / "csv"
    
    print("ğŸš€ Starting data import process...")
    print(f"Database: {DB_CONFIG['user']}@{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}")
    
    # ã‚¤ãƒ³ãƒãƒ¼ãƒˆé †åºï¼ˆå¤–éƒ¨ã‚­ãƒ¼åˆ¶ç´„ã‚’è€ƒæ…®ï¼‰
    import_order = [
        ("sales_representatives.csv", "sales_representatives"),
        ("customers.csv", "customers"),
        ("products.csv", "products"),
        ("holdings.csv", "holdings"),
        ("sales_notes.csv", "sales_notes"),
        ("cash_inflows.csv", "cash_inflows"),
        ("economic_events.csv", "economic_events"),
    ]
    
    for csv_file, table_name in import_order:
        csv_path = csv_dir / csv_file
        if csv_path.exists():
            import_csv_to_table(csv_path, table_name)
        else:
            print(f"âš ï¸  CSV file not found: {csv_path}")
    
    print("âœ¨ Data import process completed!")

if __name__ == "__main__":
    main()
